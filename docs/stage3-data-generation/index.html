<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="text/html; charset=utf-8" http-equiv="Content-Type">
<title>Stage 3: Data Generation - ManipAsInSim's Sim-to-Real Tutorial</title>
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<meta name="generator" content="mkdocs-1.6.1, mkdocs-gitbook-1.0.7">
<meta name="author" content="ManipAsInSim Team">
<link rel="shortcut icon" href="../images/favicon.ico" type="image/x-icon">
<meta name="HandheldFriendly" content="true"/>
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black">
<meta rel="next" href="" />
<link href="../css/style.min.css" rel="stylesheet">
<link href="../assets/_mkdocstrings.css" rel="stylesheet">
<link href="../custom.css" rel="stylesheet"> 
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>
<div class="book">
<div class="book-summary">
<div id="book-search-input" role="search">
<input type="text" placeholder="Type to search" />
</div> <!-- end of book-search-input -->

<nav role="navigation">
<ul class="summary">
<li>
<a href=".."  class="custom-link">ManipAsInSim's Sim-to-Real Tutorial</a>
</li>
<li class="divider"></li>
<li class="header"><a href="../stage1-task-scene-construction/index.html" class="">Stage 1 - Task and Scene Construction</a></li>

<li>
<a href="../stage1-task-scene-construction#overview" class="">Overview</a>
</li>

<li>
<a href="../stage1-task-scene-construction#task-example" class="">Task Example</a>
</li>

<li>
<a href="../stage1-task-scene-construction#code-reference" class="">Code Reference</a>
</li>

<li>
<a href="../stage1-task-scene-construction#next-steps" class="">Next Steps</a>
</li>

<li class="header"><a href="../stage2-calibration/index.html" class="">Stage 2 - Camera Calibration</a></li>

<li>
<a href="../stage2-calibration#overview" class="">Overview</a>
</li>

<li>
<a href="../stage2-calibration#calibration-workflow" class="">Calibration Workflow</a>
</li>

<li>
<a href="../stage2-calibration#advanced-techniques" class="">Advanced Techniques</a>
</li>

<li>
<a href="../stage2-calibration#code-reference" class="">Code Reference</a>
</li>

<li>
<a href="../stage2-calibration#calibration-data-management" class="">Calibration Data Management</a>
</li>

<li>
<a href="../stage2-calibration#next-steps" class="">Next Steps</a>
</li>

<li class="header"><a href="../stage3-data-generation/index.html">Stage 3 - Data Generation</a></li>

<li>
<a href="../stage3-data-generation#overview" class="">Overview</a>
</li>

<li>
<a href="../stage3-data-generation#data-collection" class="">Data Collection</a>
</li>

<li class="subheader">
<a href="../stage3-data-generation#task-decomposition-and-annotation" class="">Task Decomposition and Annotation</a>
</li>

<li class="subitem">
<a href="../stage3-data-generation#kitchen-task-subtask" class="">Kitchen task example</a>
</li>

<li class="subitem">
<a href="../stage3-data-generation#canteen-task-subtask" class="">Canteen task example</a>
</li>

<li>
<a href="../stage3-data-generation#large-scale-data-generation" class="">Large-scale Data Generation</a>
</li>

<li>
<a href="../stage3-data-generation#detail-of-wbcmimicgen" class="">Detail of WBCMimicGen</a>
</li>

<li class="subitem">
  <a href="../stage3-data-generation#data-generation-of-mobile-manipulator" class="">Data Generation of Mobile Manipulator</a>
</li>

<li>
<a href="../stage3-data-generation#code-reference" class="">Code Reference</a>
</li>

<li>
<a href="../stage3-data-generation#next-steps" class="">Next Steps</a>
</li>

<li class="header"><a href="../stage4-imitation-learning-deployment/index.html" class="">Stage 4 - Imitation Learning and Deployment</a></li>

<li>
<a href="../stage4-imitation-learning-deployment#overview" class="">Overview</a>
</li>

<li>
<a href="../stage4-imitation-learning-deployment#policy-training" class="">Policy Training</a>
</li>

<li>
<a href="../stage4-imitation-learning-deployment#real-world-deployment" class="">Real-World Deployment</a>
</li>

<li>
<a href="../stage4-imitation-learning-deployment#code-reference" class="">Code Reference</a>
</li>

<li class="divider"></li>



<li><a href="http://www.mkdocs.org">
Published with MkDocs
</a></li>

<li><a href="https://github.com/GitbookIO/theme-default">
Theme by GitBook
</a></li>
</ul>

</nav>

</div> <!-- end of book-summary -->

<div class="book-body">
<div class="body-inner">
<div class="book-header" role="navigation">

<!-- Title -->
<h1>
<i class="fa fa-circle-o-notch fa-spin"></i>
<a href="." ></a>
</h1>

</div> <!-- end of book-header -->

<div class="page-wrapper" tabindex="-1" role="main">
<div class="page-inner">
<div id="book-search-results">
<div class="search-noresults">

<section class="normal markdown-section">



<h1 id="stage-3-data-generation">Stage 3: Data Generation with WBCMimicGen<a class="headerlink" href="#stage-3-data-generation" title="Permanent link"></a></h1>
<h2 id="overview" style="margin: 10px 0; padding: 0px">Overview<a class="headerlink" href="#overview" title="Permanent link"></a></h2>

<div style="margin: 0px 0px 20px 0px; padding: 0px 0; background: linear-gradient(to right, #f8f9fa, #ffffff); border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.08);">
  <div style="position: relative; width: 100%; max-width: 1200px; margin: 0 auto; overflow-x: auto;">
  <img src="../images/stage-pictures/cdm-pipeline-seq-stage-3.png" alt="ManipAsInSim Pipeline Overview" style="width: 100%; height: auto; display: block; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
  </div>
</div>

<p>Data generation for robotic manipulation encompasses multiple approaches, each with distinct advantages and limitations. Motion planning excels at atomic task execution but requires extensive manual implementation for complex sequences. Reinforcement learning addresses highly dynamic tasks with fine-grained control requirements, though reward engineering remains challenging. MimicGen-based methods bridge this gap by leveraging human demonstrations for contact-rich manipulation while achieving the requisite scale for effective learning, particularly in long-horizon tasks. However, direct teleoperation in simulation often produces discontinuous trajectories. To address this limitation, we integrate Whole Body Control (WBC) into the MimicGen framework, yielding WBCMimicGen—a method that generates smooth trajectories while enabling coordinated control of multi-arm mobile manipulators. Implementation details are provided <a href="#detail-of-wbcmimicgen">below</a>.</p>
<p>Our approach demonstrates significant data amplification: from 3-5 human demonstrations per task, we generate thousands of trajectory variants with diverse object configurations, as exemplified in the kitchen and canteen scenarios.</p>
<!-- ## Teleoperation System

### Hardware Configuration

Teleoperation system setup:

1. **Input Devices**

   - Meta Quest: Immersive VR control
   - Keyboard: Mode switching

2. **Feedback System**

   - Visual feedback: Multi-view real-time rendering


![Image #1](images/00ffea.png) -->

<h2 id="data-collection">Data Collection<a class="headerlink" href="#data-collection" title="Permanent link"></a></h2>

<p>WBCMimicGen begins with human demonstration collection via a VR-based teleoperation system, as illustrated below:</p>
<div style="display: flex; gap: 20px; width: 100%;">
<div style="flex: 1;">
  <video controls autoplay loop muted style="width: 100%; height: auto; object-fit: cover;">
    <source src="../videos/teleop.mp4" type="video/mp4">
  </video>
</div>
</div>
<p>Representative demonstrations from both task domains:</p>
<div style="display: flex; gap: 20px; width: 100%;">
    <div style="flex: 1;">
      <video controls autoplay loop muted style="width: 100%; height: auto; object-fit: cover;">
        <source src="../videos/sim/clean_plate/episode_0_camera_0.mp4" type="video/mp4">
      </video>
    </div>
    <div style="flex: 1;">
      <video controls autoplay loop muted style="width: 100%; height: auto; object-fit: cover;">
        <source src="../videos/sim/microwave_source_demo/episode_0_camera_0.mp4" type="video/mp4">
      </video>
    </div>
  </div>

<h2 id="task-decomposition-and-annotation">Task Decomposition and Annotation<a class="headerlink" href="#task-decomposition-and-annotation" title="Permanent link"></a></h2>
<p>WBCMimicGen decomposes trajectories into object-centric subtasks and applies spatial transformations to generate diverse training scenarios. This hierarchical decomposition follows task semantics and requires either manual or automated annotation of trajectory segments to encode subtask boundaries and objectives.</p>

<p>We illustrate the decomposition strategy through two representative examples:</p>

<h3 id="kitchen-task-subtask">Kitchen task example<a class="headerlink" href="#kitchen-task-subtask" title="Permanent link"></a></h3>
<p>Kitchen task decomposition:</p>
<p><strong>Stage 1: grasp bowl</strong></p>
<ul>
<li>Start: Robot initial position</li>
<li>Goal: Bowl stably grasped</li>
</ul>
<p><strong>Stage 2: place in microwave</strong></p>
<ul>
<li>Start: Bowl grasped</li>
<li>Goal: Bowl placed inside microwave</li>
</ul>
<p><strong>Stage 3: close microwave door</strong></p>
<ul>
<li>Start: Bowl inside microwave</li>
<li>Goal: Microwave door closed</li>
</ul>
<div style="position: relative; width: 100%; max-width: 800px; margin: 0 auto;">
  <div style="overflow: hidden; width: 100%;">
    <div id="microwave-carousel" style="display: flex !important; gap: 20px; transition: transform 0.3s ease; width: max-content;">
      <div style="width: 380px; flex-shrink: 0;">
        <video controls autoplay loop muted style="width: 100%; height: auto; object-fit: cover;">
          <source src="../videos/sim/microwave_source_demo_subtask/pick_bowl.mp4" type="video/mp4">
        </video>
        <p style="text-align: center;">Grasp bowl</p>
      </div>
      <div style="width: 380px; flex-shrink: 0;">
        <video controls autoplay loop muted style="width: 100%; height: auto; object-fit: cover;">
          <source src="../videos/sim/microwave_source_demo_subtask/place_bowl.mp4" type="video/mp4">
        </video>
        <p style="text-align: center;">Place in microwave</p>
      </div>
      <div style="width: 380px; flex-shrink: 0;">
        <video controls autoplay loop muted style="width: 100%; height: auto; object-fit: cover;">
          <source src="../videos/sim/microwave_source_demo_subtask/close_door.mp4" type="video/mp4">
        </video>
        <p style="text-align: center;">Close microwave door</p>
      </div>
    </div>
  </div>
  <button onclick="var el = document.getElementById('microwave-carousel'); var current = parseInt(el.style.transform.replace(/[^\d-]/g, '') || 0); el.style.transform = 'translateX(' + Math.min(0, current + 400) + 'px)'" style="position: absolute; left: 10px; top: 50%; transform: translateY(-50%); background: rgba(0,0,0,0.5); color: white; border: none; padding: 10px; cursor: pointer; border-radius: 5px;">❮</button>
  <button onclick="var el = document.getElementById('microwave-carousel'); var current = parseInt(el.style.transform.replace(/[^\d-]/g, '') || 0); el.style.transform = 'translateX(' + Math.max(-400, current - 400) + 'px)'" style="position: absolute; right: 10px; top: 50%; transform: translateY(-50%); background: rgba(0,0,0,0.5); color: white; border: none; padding: 10px; cursor: pointer; border-radius: 5px;">❯</button>
</div>
<h3 id="canteen-task-subtask">Canteen task example<a class="headerlink" href="#canteen-task-subtask" title="Permanent link"></a></h3>
<p>Canteen task decomposition:</p>
<p><strong>Stage 1: grasp fork</strong></p>
<ul>
<li>Start: Robot initial position</li>
<li>Goal: Fork stably grasped</li>
</ul>
<p><strong>Stage 2: place fork</strong></p>
<ul>
<li>Start: Fork stably grasped</li>
<li>Goal: Fork placed in the blanket</li>
</ul>
<p><strong>Stage 3: grasp plate</strong></p>
<ul>
<li>Start: Fork placed in the blanket</li>
<li>Goal: Plate stably grasped</li>
</ul>
<p><strong>Stage 4: Drop plate</strong></p>
<ul>
<li>Start: Plate stably grasped</li>
<li>Goal: Drop above the left blanket</li>
</ul>
<p><strong>Stage 5: Place plate</strong></p>
<ul>
<li>Start: Drop above the left blanket</li>
<li>Goal: Plate placed in the blanket</li>
</ul>
<div style="position: relative; width: 100%; max-width: 800px; margin: 0 auto;">
  <div style="overflow: hidden; width: 100%;">
    <div id="clean-plate-carousel" style="display: flex !important; gap: 20px; transition: transform 0.3s ease; width: max-content;">
      <div style="width: 380px; flex-shrink: 0;">
        <video controls autoplay loop muted style="width: 100%; height: auto; object-fit: cover;">
          <source src="../videos/sim/clean_plate_subtask/pick_fork.mp4" type="video/mp4">
        </video>
        <p style="text-align: center;">Grasp fork</p>
      </div>
      <div style="width: 380px; flex-shrink: 0;">
        <video controls autoplay loop muted style="width: 100%; height: auto; object-fit: cover;">
          <source src="../videos/sim/clean_plate_subtask/place_fork.mp4" type="video/mp4">
        </video>
        <p style="text-align: center;">Place fork</p>
      </div>
      <div style="width: 380px; flex-shrink: 0;">
        <video controls autoplay loop muted style="width: 100%; height: auto; object-fit: cover;">
          <source src="../videos/sim/clean_plate_subtask/pick_plate.mp4" type="video/mp4">
        </video>
        <p style="text-align: center;">Grasp plate</p>
      </div>
      <div style="width: 380px; flex-shrink: 0;">
        <video controls autoplay loop muted style="width: 100%; height: auto; object-fit: cover;">
          <source src="../videos/sim/clean_plate_subtask/drop_plate.mp4" type="video/mp4">
        </video>
        <p style="text-align: center;">Drop plate</p>
      </div>
      <div style="width: 380px; flex-shrink: 0;">
        <video controls autoplay loop muted style="width: 100%; height: auto; object-fit: cover;">
          <source src="../videos/sim/clean_plate_subtask/place_plate.mp4" type="video/mp4">
        </video>
        <p style="text-align: center;">Place plate</p>
      </div>
    </div>
  </div>
  <button onclick="var el = document.getElementById('clean-plate-carousel'); var current = parseInt(el.style.transform.replace(/[^\d-]/g, '') || 0); el.style.transform = 'translateX(' + Math.min(0, current + 400) + 'px)'" style="position: absolute; left: 10px; top: 50%; transform: translateY(-50%); background: rgba(0,0,0,0.5); color: white; border: none; padding: 10px; cursor: pointer; border-radius: 5px;">❮</button>
  <button onclick="var el = document.getElementById('clean-plate-carousel'); var current = parseInt(el.style.transform.replace(/[^\d-]/g, '') || 0); el.style.transform = 'translateX(' + Math.max(-1200, current - 400) + 'px)'" style="position: absolute; right: 10px; top: 50%; transform: translateY(-50%); background: rgba(0,0,0,0.5); color: white; border: none; padding: 10px; cursor: pointer; border-radius: 5px;">❯</button>
</div>
<h2 id="large-scale-data-generation">Large-scale Data Generation<a class="headerlink" href="#large-scale-data-generation" title="Permanent link"></a></h2>

<p>Following task decomposition and annotation, WBCMimicGen generates large-scale training data with systematic variations:</p>
<div style="display: flex; gap: 20px; width: 100%;">
  <div style="flex: 1;">
    <video controls autoplay loop muted style="width: 100%; height: auto; object-fit: cover;">
      <source src="../videos/sim/large-scale-generate.mp4" type="video/mp4">
    </video>
  </div>
</div>

<h2 id="detail-of-wbcmimicgen">Detail of WBCMimicGen<a class="headerlink" href="#detail-of-wbcmimicgen" title="Permanent link"></a></h2>
<p>WBCMimicGen extends the MimicGen framework through whole-body control optimization:</p>

<p>Unlike standard MimicGen's linear interpolation of end-effector poses, WBCMimicGen formulates trajectory generation as a quadratic programming (QP) problem that optimizes joint velocities while respecting manipulability constraints, joint limits, and velocity bounds. This approach yields smoother, dynamically feasible demonstrations.

Formally, the trajectory generation problem seeks joint velocities $\boldsymbol x$ that track desired end-effector velocities, formulated as<a href="#ref-1">[1]</a>:

\begin{equation}
\min _ { \boldsymbol{x} } \quad f _ { o } ( \boldsymbol{x} ) = \frac { 1 } { 2 } \boldsymbol{x} ^ { \top } Q \boldsymbol{x} + \mathcal { C } ^ { \top } \boldsymbol{x}  
\end{equation}
\begin{equation*}
\begin{aligned}
\text{subject to } \mathcal { J } \boldsymbol{x} &= { } ^ { b } \nu _ { e }~, \\
\mathcal { A } \boldsymbol{x} &\leq \mathcal { B }~, \\
\mathcal { X } ^ { - } &\leq \boldsymbol{x} \leq \mathcal { X } ^ { + }~,
\end{aligned}
\end{equation*} 
</p>

<p>
  where $x = (a_\text{base}, \dot{q}_\text{active}, \delta_1, \delta_2, \cdots, \delta_i)$ and $\mathcal{X}^{+, -}$ is the limits; $a_\text{base}$ is the velocities of the robot base; $\dot{q}_\text{active}$ is the velocity of the joints related to the end-effectors in the QP (so called the active joints); $\delta_i$ are slack variables that can help construct a solvable QP. Without loss of generality, suppose there are $k$ end-effectors and $n$ joints, these variables can be expressed as:
  \begin{equation}
      \begin{aligned}
          \mathcal Q &= \text{diag}(\lambda_q, \lambda_{\delta_1}, \cdots, \lambda_{\delta_k}) \in \mathbb R^{(n+6k)}~, \\
  \mathcal { C } &= \left( \begin{array} { c } \hat { \mathbf { J } } _ { m } + \epsilon \\ 0 _ { 6k \times 1 } \end{array} \right) \in \mathbb { R } ^ { ( n + 6k ) }~, \\
  \mathcal{A} &= (\boldsymbol{1} _{n \times (n+6k)}) \in \mathbb{R}^{n \times (n + 6k)}~, \\
  \mathcal B &= \left( \begin{array} { c } 0 _ { b } \\ \eta \frac { \rho _ { 0 } - \rho _ { s } } { \rho _ { i } - \rho _ { s } } \\ \vdots \\ \eta \frac { \rho _ { n } - \rho _ { s } } { \rho _ { i } - \rho _ { s } } \end{array} \right) \in \mathbb { R } ^ { n }~.
      \end{aligned}
  \end{equation}
</p>


<p>Comparative analysis demonstrates WBCMimicGen's superior trajectory smoothness (right) versus standard MimicGen (left):</p>

<div style="display: flex; gap: 20px; width: 100%;">
  <div style="flex: 1;">
    <video controls autoplay loop muted style="width: 100%; height: auto; object-fit: cover;">
      <source src="../videos/compare_with_mimicgen/microwave_mimicgen-1.mp4" type="video/mp4">
    </video>
    <p style="text-align: center;">Kitchen task's data generated by MimicGen</p>
  </div>
  <div style="flex: 1;">
    <video controls autoplay loop muted style="width: 100%; height: auto; object-fit: cover;">
      <source src="../videos/compare_with_mimicgen/microwave_wbc-1.mp4" type="video/mp4">
    </video>
    <p style="text-align: center;">Kitchen task's data generated by WBCMimicGen</p>
  </div>
</div>
<div style="display: flex; gap: 20px; width: 100%;">
  <div style="flex: 1;">
    <video controls autoplay loop muted style="width: 100%; height: auto; object-fit: cover;">
      <source src="../videos/compare_with_mimicgen/plate_mimicgen-1.mp4" type="video/mp4">
    </video>
    <p style="text-align: center;">Canteen task's data generated by MimicGen</p>
  </div>
  <div style="flex: 1;">
    <video controls autoplay loop muted style="width: 100%; height: auto; object-fit: cover;">
      <source src="../videos/compare_with_mimicgen/plate_wbc-1.mp4" type="video/mp4">
    </video>
    <p style="text-align: center;">Canteen task's data generated by WBCMimicGen</p>
  </div>
</div>

<h3 id="data-generation-of-mobile-manipulator">Data Generation of Mobile Manipulator<a class="headerlink" href="#data-generation-of-mobile-manipulator" title="Permanent link"></a></h3>
<p>A key innovation of WBCMimicGen is its extension to mobile manipulation. The following demonstration shows coordinated base-arm control on the ARX7 platform executing a multi-stage task: grasping toothpaste, placing it in a cup, and repositioning the cup:</p>

<div style="display: flex; gap: 20px; width: 100%;">
  <div style="flex: 1;">
    <video controls autoplay loop muted style="width: 100%; height: auto; object-fit: cover;">
      <source src="../videos/sim/arx7/arx-camera-0.mp4" type="video/mp4">
    </video>
    <p style="text-align: center;">Camera on the robot's head.</p>
  </div>
  <div style="flex: 1;">
    <video controls autoplay loop muted style="width: 100%; height: auto; object-fit: cover;">
      <source src="../videos/sim/arx7/arx-camera-top.mp4" type="video/mp4">
    </video>
    <p style="text-align: center;">Camera in the environment.</p>
  </div>
</div>

<h2 id="code-reference">Code Reference<a class="headerlink" href="#code-reference" title="Permanent link"></a></h2>
<p>Data generation related code:</p>
<p><strong>Teleoperation System:</strong></p>
<ul>
<li>Quest VR control: <code><a href="https://github.com/ByteDance-Seed/manip-as-in-sim-suite/blob/main/wbcmimic/scripts/basic/record_demos_ur5_quest.py">https://github.com/ByteDance-Seed/manip-as-in-sim-suite/blob/main/wbcmimic/scripts/basic/record_demos_ur5_quest.py</a></code></li>
</ul>
<p><strong>Data Annotation Scripts:</strong></p>
<ul>
<li>
  <code><a href="https://github.com/ByteDance-Seed/manip-as-in-sim-suite/blob/main/wbcmimic/scripts/mimicgen/annotate_demos.py">https://github.com/ByteDance-Seed/manip-as-in-sim-suite/blob/main/wbcmimic/scripts/mimicgen/annotate_demos.py</a></code>
</li>
</ul>
<p><strong>Data Generation Scripts:</strong></p>
<ul>
<li>Generation configuration: <code><a href="https://github.com/ByteDance-Seed/manip-as-in-sim-suite/blob/main/wbcmimic/config/mimicgen/generate_data.yaml">https://github.com/ByteDance-Seed/manip-as-in-sim-suite/blob/main/wbcmimic/config/mimicgen/generate_data.yaml</a></code></li>
<li>Generation script: <code><a href="https://github.com/ByteDance-Seed/manip-as-in-sim-suite/blob/main/wbcmimic/scripts/mimicgen/run_hydra.py">https://github.com/ByteDance-Seed/manip-as-in-sim-suite/blob/main/wbcmimic/scripts/mimicgen/run_hydra.py</a></code></li>
</ul>
<h2 id="next-steps">Next Steps<a class="headerlink" href="#next-steps" title="Permanent link"></a></h2>
<p>The generated dataset enables subsequent imitation learning for policy training and real-world deployment, detailed in Stage 4.</p>

<h2 id="references">References<a class="headerlink" href="#references" title="Permanent link"></a></h2>
<p id="ref-1"> [1] Jesse Haviland, Niko Sünderhauf, and Peter Corke. A holistic approach to reactive mobile manipulation. IEEE
  Robotics and Automation Letters, 7(2):3122–3129, 2022. </p>
</section>
</div> <!-- end of search-noresults -->
<div class="search-results">
<div class="has-results">

<h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
<ul class="search-results-list"></ul>

</div> <!-- end of has-results -->
<div class="no-results">

<h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>

</div> <!-- end of no-results -->
</div> <!-- end of search-results -->
</div> <!-- end of book-search-results -->

</div> <!-- end of page-inner -->
</div> <!-- end of page-wrapper -->

</div> <!-- end of body-inner -->

</div> <!-- end of book-body -->
<style>
/* Hide search results by default */
#book-search-results .search-results {
    display: none;
}
#book-search-results.active .search-noresults {
    display: none;
}
#book-search-results.active .search-results {
    display: block;
}
</style>
<script>
var base_url = '..';
var min_search_length = 3;
</script>
<script src="../js/main.js"></script>
<script src="../search/main.js"></script>
<script src="../js/gitbook.min.js"></script>
<script src="../js/theme.min.js"></script>
<script src="../js/nav-hierarchy.js"></script>
<script>
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      processEscapes: true
    }
  };
</script>
</body>
</html>